{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_dir = Path('.').absolute().parent\n",
    "\n",
    "# Model dir: Directory containing saved A1GymEnv-v0.zip model\n",
    "model_dir = project_dir / 'logs' / 'ppo' / 'A1GymEnv-v0_38'\n",
    "# Stats dir: Directory containing statistics logged with scripts/enjoy_with_logging.py\n",
    "stats_dir = model_dir / 'stats'\n",
    "# Params dir: Directory to save model weights, motion capture parameters, etc.\n",
    "params_dir = model_dir / 'parameters'\n",
    "params_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=73, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=256, out_features=12, bias=True)\n",
      ")\n",
      "0_weight torch.Size([256, 73])\n",
      "0_bias torch.Size([256, 1])\n",
      "2_weight torch.Size([256, 256])\n",
      "2_bias torch.Size([256, 1])\n",
      "4_weight torch.Size([12, 256])\n",
      "4_bias torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "# Export model weights\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utils import ALGOS\n",
    "\n",
    "model_path = model_dir / \"A1GymEnv-v0.zip\"\n",
    "model = ALGOS[\"ppo\"].load(model_path)\n",
    "\n",
    "def extract_policy_layers(model):\n",
    "    mlp_extractor = model.policy.mlp_extractor.policy_net\n",
    "    action_net = model.policy.action_net\n",
    "\n",
    "    layers = []\n",
    "    for m in mlp_extractor.modules():\n",
    "        if not isinstance(m, nn.Sequential):\n",
    "            layers.append(m)\n",
    "    layers.append(action_net)\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def save_tensor_as_csv(path, t: torch.Tensor):\n",
    "    t_np = t.detach().cpu().numpy()\n",
    "    np.savetxt(path, t_np, delimiter = ',')\n",
    "\n",
    "# Extract relevant layers of PPO actor network\n",
    "policy_net = extract_policy_layers(model)\n",
    "policy_net.eval()\n",
    "print(policy_net)\n",
    "\n",
    "# Export model weights as csv\n",
    "for name, param in policy_net.named_parameters():\n",
    "    if len(param.size()) == 1:\n",
    "        param = torch.unsqueeze(param, axis=-1)\n",
    "    name = name.replace('.', '_')\n",
    "    print(name, param.size())\n",
    "    save_tensor_as_csv(params_dir / f'{name}.csv', param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 73) (1, 73)\n"
     ]
    }
   ],
   "source": [
    "# Export normalizer parameters\n",
    "import pickle\n",
    "normalizer_path = model_dir / \"A1GymEnv-v0\" / \"vecnormalize.pkl\"\n",
    "with open(normalizer_path, \"rb\") as pkl:\n",
    "    normalizer = pickle.load(pkl)\n",
    "\n",
    "obs_mean = normalizer.obs_rms.mean \n",
    "obs_std = np.sqrt(normalizer.obs_rms.var + normalizer.epsilon)\n",
    "obs_mean = obs_mean.reshape(1,-1)\n",
    "obs_std = obs_std.reshape(1,-1)\n",
    "print(obs_mean.shape, obs_std.shape)\n",
    "\n",
    "np.savetxt(params_dir / 'obs_mean.csv', obs_mean, delimiter = ',')\n",
    "np.savetxt(params_dir / 'obs_std.csv', obs_std, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.67 -1.25  0.    0.67 -1.25  0.    0.67 -1.25  0.    0.67 -1.25]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/rl-baselines-zoo-cu113/lib/python3.8/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "# Export default pose and motor polarity\n",
    "from blind_walking.envs.env_wrappers import simple_openloop\n",
    "\n",
    "pose_offset = simple_openloop.LaikagoPoseOffsetGenerator()._pose.reshape(1,-1)\n",
    "np.savetxt(params_dir / 'pose_offset.csv', pose_offset, delimiter = ',')\n",
    "print(pose_offset)\n",
    "\n",
    "motor_polarity = np.array([1, -1, -1] * 4).reshape(1,-1)\n",
    "np.savetxt(params_dir / 'motor_signs.csv', motor_polarity, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export recorded motion \n",
    "motion_logs = (\n",
    "    \"motor_position\",\n",
    "    \"motor_velocity\",\n",
    "    \"motor_torque\",\n",
    "    \"base_rpy\",\n",
    "    \"base_rpy_rate\",\n",
    "    \"base_pos\",\n",
    "    \"base_vel\",\n",
    "    \"time\",\n",
    ")\n",
    "\n",
    "nn_logs = (\n",
    "    \"nn_observation\",\n",
    "    \"nn_action\",\n",
    ")\n",
    "\n",
    "all_logs = motion_logs + nn_logs\n",
    "\n",
    "def to_camel_case(snake_str):\n",
    "    components = snake_str.split('_')\n",
    "    # We capitalize the first letter of each component except the first one\n",
    "    # with the 'title' method and join them together.\n",
    "    return components[0] + ''.join(x.title() for x in components[1:])\n",
    "\n",
    "def export_logged_traj(stat_dir, param_dir, name):\n",
    "    \"\"\" Export statistics logged as .npy files and save in CSV format. \"\"\"\n",
    "    inp_name = name\n",
    "    traj = np.load(str(stat_dir / f'{inp_name}.npy'))    \n",
    "    traj = np.squeeze(traj)\n",
    "    \n",
    "    oup_name = to_camel_case(name)\n",
    "    np.savetxt(str(param_dir / f'{oup_name}.csv'), traj, delimiter=',')\n",
    "\n",
    "for log_name in all_logs:\n",
    "    try:\n",
    "        export_logged_traj(stats_dir, params_dir, log_name)\n",
    "    except FileNotFoundError:\n",
    "        # If relevant log isn't found, skip\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export sample in-out pairs\n",
    "import json\n",
    "\n",
    "input_dim = obs_mean.shape[1]\n",
    "policy_net.eval()\n",
    "policy_net = policy_net.to(torch.device('cpu'))\n",
    "sample_output_dir = model_dir / 'sample_inp_oup'\n",
    "sample_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "sample_inputs = {\n",
    "    'zeros': torch.zeros(1, input_dim),\n",
    "    'ones': torch.ones(1, input_dim)\n",
    "}\n",
    "inp_oup_names = {}\n",
    "for name, inp_value in sample_inputs.items():\n",
    "    inp_name = name + '_in.csv'\n",
    "    oup_name = name + '_out.csv'\n",
    "    inp_oup_names[inp_name] = oup_name\n",
    "    oup_value = policy_net(inp_value)\n",
    "    save_tensor_as_csv(sample_output_dir / inp_name, inp_value)\n",
    "    save_tensor_as_csv(sample_output_dir / oup_name, oup_value)\n",
    "\n",
    "with open(sample_output_dir / 'inp_oup_name_pairs.txt', 'w') as file:\n",
    "    for inp_name, oup_name in inp_oup_names.items():\n",
    "        line = ','.join([inp_name, oup_name]) + \"\\n\"\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init CPG gait=walk, duty_factor=0.75, period=0.6666666666666666\n",
      "argv[0]=\n",
      "(2, 12) (2, 12)\n",
      "[[ 1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.77567951 -0.77567951 -0.77567951 -0.77567951 -0.77567951 -0.77567951\n",
      "  -0.77567951 -0.77567951 -0.77567951 -0.77567951 -0.77567951 -0.77567951]]\n",
      "[[ 1.10600612e-02 -9.02221201e-01  1.79002986e+00  7.03036845e-03\n",
      "  -9.00670278e-01  1.79169263e+00  3.93621176e-03 -9.17063149e-01\n",
      "   1.78842902e+00  4.71211854e-05 -9.06194896e-01  1.80551041e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Export butterworth filter coefficients and history\n",
    "import gym \n",
    "import numpy as np\n",
    "import utils.import_envs\n",
    "env = gym.make(\"A1GymEnv-v0\")\n",
    "env.reset()\n",
    "\n",
    "filter = env.robot._action_filter\n",
    "a = filter.a.T.copy()\n",
    "b = filter.b.T.copy()\n",
    "print(a.shape, b.shape)\n",
    "print(a)\n",
    "\n",
    "np.savetxt(params_dir / 'filter_a_coeff.csv', a, delimiter =',')\n",
    "np.savetxt(params_dir / 'filter_b_coeff.csv', b, delimiter =',')\n",
    "\n",
    "initial_motor_pos = env.robot.GetMotorAngles() * motor_polarity\n",
    "print(initial_motor_pos)\n",
    "np.savetxt(params_dir / 'final_motor_position.csv', initial_motor_pos, delimiter=',')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee3bb4c681c16afaca5ce5daeb93e1cbe02bcdb573b5a82c4c5cf6b16d9005d5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('rl-baselines-zoo-cu113')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
