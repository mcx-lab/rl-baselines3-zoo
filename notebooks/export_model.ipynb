{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model Artifacts\n",
    "\n",
    "## Setup\n",
    "\n",
    "Configure `model_dir` below to the directory containing the `A1GymEnv-v0.zip` model. \n",
    "If necessary, set `stats_dir` as well to the subfolder containing the recorded statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_dir = Path('.').absolute().parent\n",
    "model_dir = project_dir / 'debug_logs' / 'ppo' / 'A1GymEnv-v0_6'\n",
    "stats_dir = model_dir / 'stats'\n",
    "\n",
    "\n",
    "params_dir = model_dir / 'parameters'\n",
    "params_dir.mkdir(exist_ok=True, parents=True)\n",
    "sample_inp_oup_dir = model_dir / 'sample_inp_oup'\n",
    "sample_inp_oup_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model\n",
    "\n",
    "The rest of the code should be runnable without any changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=73, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=256, out_features=12, bias=True)\n",
      ")\n",
      "0_weight torch.Size([256, 73])\n",
      "0_bias torch.Size([256, 1])\n",
      "2_weight torch.Size([256, 256])\n",
      "2_bias torch.Size([256, 1])\n",
      "4_weight torch.Size([12, 256])\n",
      "4_bias torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "# Extract actor network from SB3 PPO policy\n",
    "# Export actor network weights\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utils import ALGOS\n",
    "\n",
    "model_path = model_dir / \"A1GymEnv-v0.zip\"\n",
    "model = ALGOS[\"ppo\"].load(model_path)\n",
    "\n",
    "def extract_policy_layers(model):\n",
    "    mlp_extractor = model.policy.mlp_extractor.policy_net\n",
    "    action_net = model.policy.action_net\n",
    "\n",
    "    layers = []\n",
    "    for m in mlp_extractor.modules():\n",
    "        if not isinstance(m, nn.Sequential):\n",
    "            layers.append(m)\n",
    "    layers.append(action_net)\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def save_tensor_as_csv(path, t: torch.Tensor):\n",
    "    t_np = t.detach().cpu().numpy()\n",
    "    np.savetxt(path, t_np, delimiter = ',')\n",
    "\n",
    "policy_net = extract_policy_layers(model)\n",
    "policy_net.eval()\n",
    "print(policy_net)\n",
    "\n",
    "for name, param in policy_net.named_parameters():\n",
    "    if len(param.size()) == 1:\n",
    "        param = torch.unsqueeze(param, axis=-1)\n",
    "    name = name.replace('.', '_')\n",
    "    print(name, param.size())\n",
    "    save_tensor_as_csv(params_dir / f'{name}.csv', param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 73) (1, 73)\n"
     ]
    }
   ],
   "source": [
    "# Export normalizer parameters\n",
    "import pickle\n",
    "normalizer_path = model_dir / \"A1GymEnv-v0\" / \"vecnormalize.pkl\"\n",
    "with open(normalizer_path, \"rb\") as pkl:\n",
    "    normalizer = pickle.load(pkl)\n",
    "\n",
    "obs_mean = normalizer.obs_rms.mean \n",
    "obs_std = np.sqrt(normalizer.obs_rms.var + normalizer.epsilon)\n",
    "obs_mean = obs_mean.reshape(1,-1)\n",
    "obs_std = obs_std.reshape(1,-1)\n",
    "print(obs_mean.shape, obs_std.shape)\n",
    "\n",
    "np.savetxt(params_dir / 'obs_mean.csv', obs_mean, delimiter = ',')\n",
    "np.savetxt(params_dir / 'obs_std.csv', obs_std, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.67 -1.25  0.    0.67 -1.25  0.    0.67 -1.25  0.    0.67 -1.25]]\n"
     ]
    }
   ],
   "source": [
    "# Export default pose and motor polarity\n",
    "from blind_walking.envs.env_wrappers import simple_openloop\n",
    "\n",
    "pose_offset = simple_openloop.LaikagoPoseOffsetGenerator()._pose.reshape(1,-1)\n",
    "np.savetxt(params_dir / 'pose_offset.csv', pose_offset, delimiter = ',')\n",
    "print(pose_offset)\n",
    "\n",
    "motor_polarity = np.array([1, -1, -1] * 4).reshape(1,-1)\n",
    "np.savetxt(params_dir / 'motor_signs.csv', motor_polarity, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export nn observations and actions\n",
    "motion_logs = (\n",
    "    \"motor_position\",\n",
    "    \"motor_velocity\",\n",
    "    \"motor_torque\",\n",
    "    \"base_rpy\",\n",
    "    \"base_rpy_rate\",\n",
    "    \"base_position\",\n",
    "    \"base_velocity\",\n",
    "    \"time\",\n",
    ")\n",
    "\n",
    "nn_logs = (\n",
    "    \"nn_observations\",\n",
    "    \"nn_actions\"\n",
    ")\n",
    "\n",
    "all_logs = motion_logs + nn_logs \n",
    "\n",
    "def to_camel_case(snake_str):\n",
    "    components = snake_str.split('_')\n",
    "    # We capitalize the first letter of each component except the first one\n",
    "    # with the 'title' method and join them together.\n",
    "    return components[0] + ''.join(x.title() for x in components[1:])\n",
    "\n",
    "def export_logged_trajectories(stat_dir, param_dir, name):\n",
    "    traj = np.load(str(stat_dir / f'{name}.npy'))\n",
    "    traj = np.squeeze(traj)\n",
    "    oup_name = to_camel_case(name)\n",
    "    np.savetxt(str(param_dir / f'{oup_name}.csv'), traj,  delimiter = ',')\n",
    "\n",
    "for log_name in all_logs:\n",
    "    export_logged_trajectories(stats_dir, params_dir, log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export sample in-out pairs\n",
    "import json\n",
    "\n",
    "input_dim = obs_mean.shape[1]\n",
    "policy_net.eval()\n",
    "policy_net = policy_net.to(torch.device('cpu'))\n",
    "\n",
    "sample_inputs = {\n",
    "    'zeros': torch.zeros(1, input_dim),\n",
    "    'ones': torch.ones(1, input_dim)\n",
    "}\n",
    "inp_oup_names = {}\n",
    "for name, inp_value in sample_inputs.items():\n",
    "    inp_name = name + '_in.csv'\n",
    "    oup_name = name + '_out.csv'\n",
    "    inp_oup_names[inp_name] = oup_name\n",
    "    oup_value = policy_net(inp_value)\n",
    "    save_tensor_as_csv(sample_inp_oup_dir / inp_name, inp_value)\n",
    "    save_tensor_as_csv(sample_inp_oup_dir / oup_name, oup_value)\n",
    "\n",
    "with open(sample_inp_oup_dir / 'inp_oup_name_pairs.txt', 'w') as file:\n",
    "    for inp_name, oup_name in inp_oup_names.items():\n",
    "        line = ','.join([inp_name, oup_name]) + \"\\n\"\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init CPG gait=walk, duty_factor=0.75, period=0.6666666666666666\n",
      "argv[0]=\n",
      "(2, 12) (2, 12)\n",
      "[[ 1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.          1.          1.          1.        ]\n",
      " [-0.77567951 -0.77567951 -0.77567951 -0.77567951 -0.77567951 -0.77567951\n",
      "  -0.77567951 -0.77567951 -0.77567951 -0.77567951 -0.77567951 -0.77567951]]\n",
      "[[-0.00237892 -0.90104205  1.79415947 -0.01273846 -0.89080655  1.8118248\n",
      "  -0.01493733 -0.91010711  1.7881657   0.01362704 -0.88808935  1.81157552]]\n"
     ]
    }
   ],
   "source": [
    "# Export butterworth filter coefficients and history\n",
    "# Export initial motor angles\n",
    "import gym \n",
    "import numpy as np\n",
    "import utils.import_envs\n",
    "env = gym.make(\"A1GymEnv-v0\")\n",
    "env.reset()\n",
    "\n",
    "filter = env.robot._action_filter\n",
    "a = filter.a.T.copy()\n",
    "b = filter.b.T.copy()\n",
    "print(a.shape, b.shape)\n",
    "print(a)\n",
    "\n",
    "np.savetxt(params_dir / 'filter_a_coeff.csv', a, delimiter =',')\n",
    "np.savetxt(params_dir / 'filter_b_coeff.csv', b, delimiter =',')\n",
    "\n",
    "initial_motor_pos = env.robot.GetMotorAngles() * motor_polarity\n",
    "print(initial_motor_pos)\n",
    "np.savetxt(params_dir / 'final_motor_position.csv', initial_motor_pos, delimiter=',')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee3bb4c681c16afaca5ce5daeb93e1cbe02bcdb573b5a82c4c5cf6b16d9005d5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('rl-baselines-zoo-cu113')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
